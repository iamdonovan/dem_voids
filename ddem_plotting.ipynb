{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from pybob.GeoImg import GeoImg\n",
    "from pybob.bob_tools import bin_data\n",
    "from pybob import image_tools as it, ddem_tools as dt, plot_tools as pt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_column(col, newsize):\n",
    "    dsize = newsize - col.size\n",
    "    return np.concatenate([col, np.nan*np.zeros(dsize)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family': 'sans',\n",
    "        'weight': 'normal',\n",
    "        'size': 24}\n",
    "legend_font = {'family': 'sans',\n",
    "               'weight': 'normal',\n",
    "               'size': '18'}\n",
    "matplotlib.rc('font', **font)\n",
    "plt.ion()\n",
    "\n",
    "boxprops = dict(linestyle='-', linewidth=2, color='k')\n",
    "medianprops = dict(linestyle='-', linewidth=2, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_markers = {'Mean dH': ('x', 'purple'), \n",
    "                  'Med. dH': ('+', 'purple'),\n",
    "                  'dH interp.': ('d', 'r'),\n",
    "                  'Z interp.': ('o', 'r'),\n",
    "                  '1km neighborhood': ('s', 'r'),\n",
    "                  'Glob. Mean Hyps.': ('^', 'k'),\n",
    "                  'Glob. Med. Hyps.': ('*', 'k'),\n",
    "                  'Glob. Poly. Hyps.': ('.', 'k'),\n",
    "                  'Loc. Mean Hyps.': ('^',  'b'),\n",
    "                  'Loc. Med. Hyps.': ('*', 'b'),\n",
    "                  'Loc. Poly. Hyps.': ('.', 'b')}\n",
    "\n",
    "label_names = {'Mean dH': 'const. mean', \n",
    "               'Med. dH': 'const. med.',\n",
    "               'dH interp.': 'lin. interp. dH',\n",
    "               'Z interp.': 'lin. interp. Z',\n",
    "               '1km neighborhood': '1km avg.',\n",
    "               'Glob. Mean Hyps.': 'Glob. Mean Hyps.',\n",
    "               'Glob. Med. Hyps.': 'Glob. Med. Hyps.',\n",
    "               'Glob. Poly. Hyps.': 'Glob. Poly. Hyps.',\n",
    "               'Loc. Mean Hyps.': 'Loc. Mean Hyps.',\n",
    "               'Loc. Med. Hyps.': 'Loc. Med. Hyps.',\n",
    "               'Loc. Poly. Hyps.': 'Loc. Poly. Hyps.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load images, data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmask = '../outlines/01_rgi60_Alaska_GlacierBay_02km_UTM.shp'\n",
    "glac_outlines = gpd.read_file(gmask)\n",
    "glac_outlines.set_index('RGIId', inplace=True)\n",
    "\n",
    "void_list = [35, 50, 70, 80, 90, 95]\n",
    "\n",
    "df = pd.read_csv('volume_change_results.csv')\n",
    "\n",
    "common_cols = ['base dV', 'Area', 'uncert.', 'dt']\n",
    "dv_cols = ['Mean dH', 'Med. dH', 'dH interp.', 'Z interp.', '1km neighborhood', 'Glob. Mean Hyps.',\n",
    "           'Glob. Med. Hyps.', 'Glob. Poly. Hyps.', 'Loc. Mean Hyps.', 'Loc. Med. Hyps.', 'Loc. Poly. Hyps.']\n",
    "df.set_index('RGIId', inplace=True)\n",
    "\n",
    "df['base dV'] = df['base dV'] / df['Area'] / df['dt'] # base dV in m/a\n",
    "df['uncert.'] = df['uncert.'] / df['Area'] / df['dt'] # uncert. in m/a\n",
    "\n",
    "for c in dv_cols:\n",
    "    for v in void_list:\n",
    "        df[c + str(v)] = df[c + str(v)] / df['Area'] / df['dt'] # dV estimates in m/a\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot comparison of interp. volume change vs measured\n",
    "\n",
    "Figure 5 from the paper, plots a direct comparison of the true and estimated volume change for the 50% correlation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "v = 50 # change this to see other thresholds (i.e., 35, 70, 80,...)\n",
    "plt.figure(facecolor='w', figsize=(12, 12), dpi=200)\n",
    "plt.plot(range(-10, 3), range(-10, 3), 'k--')\n",
    "\n",
    "for c in dv_cols:\n",
    "    if method_markers[c][0] == '.':\n",
    "        fs = 'full'\n",
    "    else:\n",
    "        fs = 'none'\n",
    "    plt.plot(df['base dV'], df[c + str(v)], method_markers[c][0], \n",
    "             color=method_markers[c][1], ms=18, label=label_names[c].lower(), \n",
    "             alpha=0.35, fillstyle=fs)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.legend(loc='lower right', prop=legend_font)\n",
    "\n",
    "\n",
    "plt.xlabel('true volume change (m a$^{-1}$)')\n",
    "plt.ylabel('void-filled volume change (m a$^{-1}$)')\n",
    "\n",
    "ax.axis('scaled')\n",
    "ax.set_xlim(-7, 1)\n",
    "ax.set_ylim(-7, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the analysis is done with the differences to the true values, so we subtract out the true volume change from each column. We also assume that any differences beyond 10 m/a are outliers, and remove them from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in void_list:\n",
    "    for c in dv_cols:\n",
    "        df[c + str(v)] = df[c + str(v)] - df['base dV']\n",
    "        df[c + str(v)][np.abs(df[c + str(v)]) > 10] = np.nan\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1\n",
    "Print Table 1 from the paper, in TeX format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = 50 # change this to see other thresholds (i.e., 35, 70, 80,...)\n",
    "print('method  & mean $\\pm$ std & median & max & min & rms diff & total diff & pct. uncert. \\\\\\\\\\hline')\n",
    "for c in dv_cols:\n",
    "    mu = df[c + str(v)].mean()\n",
    "    sig = df[c + str(v)].std()\n",
    "    med = df[c + str(v)].median()\n",
    "    max_diff = np.max(df[c + str(v)])\n",
    "    min_diff = np.min(df[c + str(v)])\n",
    "    rms = np.sqrt(np.nansum(df[c + str(v)]**2) / np.count_nonzero(~np.isnan(df[c + str(v)])))\n",
    "    total_diff = np.nansum(df[c + str(v)] * df['Area']) / 1e9\n",
    "    pct_uncert = 100 * np.count_nonzero(np.abs(df[c + str(v)]) < df['uncert.']) / df['uncert.'].size\n",
    "    #total_diff = np.nansum(df[c + str(v)])\n",
    "    print('{} & {:.2f} $\\pm$ {:.2f} & {:.2f} & {:.2f} & {:.2f} & {:.2f} & {:.2f} & {:.2f} \\\\\\\\'.format(label_names[c].lower(),\n",
    "                                                                                   mu, sig, med,\n",
    "                                                                                   max_diff, min_diff, \n",
    "                                                                                   rms, total_diff, pct_uncert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the glaciers by area (1-10 km2, 10-50 km2, 50-100 km2, over 100 km2), and show box plots for each grouping. For glaciers over 100 km2, we show their spread as individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 50 # change this to see other thresholds (i.e., 35, 70, 80,...)\n",
    "#df = df_list[i]\n",
    "binned = np.digitize(df['Area'], 1e6 * np.array([0, 10, 50, 100]))\n",
    "\n",
    "grouped = []\n",
    "for b in np.unique(binned):\n",
    "    grouped.append(df[binned == b])\n",
    "\n",
    "smallest_dV = np.nansum(grouped[0]['base dV'] * grouped[0]['Area']) / grouped[0]['Area'].sum()\n",
    "medium_dV = np.nansum(grouped[1]['base dV'] * grouped[1]['Area']) / grouped[1]['Area'].sum()\n",
    "largest_dV = np.nansum(grouped[2]['base dV'] * grouped[2]['Area']) / grouped[2]['Area'].sum()\n",
    "\n",
    "smallest = np.empty(0)\n",
    "medium = np.empty(0)\n",
    "largest = np.empty(0)\n",
    "\n",
    "for c in dv_cols:\n",
    "    smallest = np.concatenate([smallest, grouped[0][c+ str(v)]])\n",
    "    medium = np.concatenate([medium, grouped[1][c+ str(v)]])\n",
    "    largest = np.concatenate([largest, grouped[2][c+ str(v)]])\n",
    "\n",
    "medium = fill_column(medium, smallest.size)\n",
    "largest = fill_column(largest, smallest.size)\n",
    "\n",
    "grouped_data = np.vstack([smallest, medium, largest]).transpose()\n",
    "newdf = pd.DataFrame(grouped_data, columns=['1-10 km$^2$ (n={})'.format(grouped[0].shape[0]),\n",
    "                                            '10-50 km$^2$ (n={})'.format(grouped[1].shape[0]),\n",
    "                                            '50-100 km$^2$ (n={})'.format(grouped[2].shape[0])])\n",
    "\n",
    "sorted_3 = grouped[3].sort_values('Area', ascending=True)\n",
    "these_cols = [c + str(v) for c in dv_cols]\n",
    "ind_data = sorted_3[these_cols].values\n",
    "dVs = np.hstack([sorted_3['base dV'].values, largest_dV, medium_dV, smallest_dV])\n",
    "\n",
    "dsize = smallest.size - ind_data.shape[1]\n",
    "add_data = np.zeros((20, dsize)) + np.nan\n",
    "ind_data_filled = np.hstack([ind_data, add_data]).transpose()\n",
    "\n",
    "pretty_cols = [c.split('.')[1] for c in sorted_3.index[:-1]]\n",
    "ind_df = pd.DataFrame(ind_data_filled, columns=pretty_cols + [sorted_3.index[-1]])\n",
    "\n",
    "final_df = newdf.join(ind_df)\n",
    "f = plt.figure(facecolor='w', figsize=(15, 15), dpi=200)\n",
    "bp = final_df.boxplot(vert=False, return_type='dict')\n",
    "\n",
    "for key in bp.keys():\n",
    "    for item in bp[key]:\n",
    "        item.set_linewidth(2)\n",
    "        item.set_color('k')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(-1.5, 1.5)\n",
    "\n",
    "yloc = 22.7\n",
    "ax.text(1.52, yloc, '{: .2f} '.format(dVs[0]) + 'm a$^{-1}$')\n",
    "for dv in dVs[1:]:\n",
    "    yloc -= 1\n",
    "    ax.text(1.52, yloc, '{: .2f} '.format(dv))\n",
    "\n",
    "yloc = 3.7\n",
    "for a in sorted_3['Area'].values:\n",
    "    ax.text(-1.5, yloc, '{: .0f} km$^2$'.format(a / 1e6))\n",
    "    yloc += 1\n",
    "\n",
    "plt.xlabel('difference to truth (m a$^{-1}$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7\n",
    "\n",
    "Figure 7 from the paper shows how each method did relative to the the uncertainty estimates for each glacier over 100 km2. Gray bars indicate uncertainty values in m/a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_inds = np.arange(0, sorted_3.index.size, 1)\n",
    "f = plt.figure(facecolor='w', figsize=(15, 15), dpi=200)\n",
    "v = 50 # 35, 50, 70, 80, 90, 95\n",
    "plt.plot([0, 0], [-1, 20], 'k--', linewidth=2)\n",
    "errs = []\n",
    "for j in y_inds:\n",
    "    y = j - 0.5\n",
    "    x = -sorted_3['uncert.'][j]\n",
    "    errs.append(matplotlib.patches.Rectangle((x, y), 2*sorted_3['uncert.'][j], 1, facecolor='0.5', edgecolor='k'))\n",
    "    \n",
    "p = matplotlib.collections.PatchCollection(errs, alpha=0.4, facecolor='0.5', edgecolor='k')\n",
    "plt.gca().add_collection(p)   \n",
    "plt.draw()\n",
    "\n",
    "for c in dv_cols:\n",
    "    if method_markers[c][0] == '.':\n",
    "        fs = 'full'\n",
    "    else:\n",
    "        fs = 'none'\n",
    "    plt.plot(sorted_3[c + str(v)], y_inds, method_markers[c][0], color=method_markers[c][1],\n",
    "             ms=18, label=label_names[c].lower(), fillstyle=fs)\n",
    "\n",
    "plt.gca().set_yticks(y_inds)\n",
    "plt.gca().set_yticklabels(pretty_cols + [sorted_3.index[-1]])\n",
    "plt.grid(axis='y')\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-0.5, 19.5)\n",
    "plt.legend(loc='lower left', prop=legend_font)\n",
    "\n",
    "plt.xlabel('difference to truth (m a$^{-1}$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 8\n",
    "\n",
    "Figure 8 shows box plots of the difference to truth for glaciers over 100 km2, and all glaciers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig8 = plt.figure(facecolor='w', figsize=(16, 8), dpi=200)\n",
    "\n",
    "ax = fig8.add_subplot(111)    # The big subplot\n",
    "ax1 = fig8.add_subplot(121)\n",
    "ax2 = fig8.add_subplot(122)\n",
    "\n",
    "# Turn off axis lines and ticks of the big subplot\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "\n",
    "v = 50\n",
    "#new_cols = [c.lower().replace('70', '') for c in grouped[3].columns]\n",
    "#grouped[3].columns = new_cols\n",
    "these_cols = [c + str(v) for c in dv_cols[::-1]]\n",
    "new_grp = pd.concat(grouped[0:1])\n",
    "bp1 = grouped[3][these_cols].boxplot(vert=False, return_type='dict', ax=ax1)\n",
    "#bp = grouped[0][these_cols].boxplot(vert=False, return_type='dict')\n",
    "bp2 = new_grp[these_cols].boxplot(vert=False, return_type='dict', ax=ax2)\n",
    "\n",
    "for key in bp1.keys():\n",
    "    for item in bp1[key]:\n",
    "        item.set_linewidth(2)\n",
    "        item.set_color('k')\n",
    "for key in bp2.keys():\n",
    "    for item in bp2[key]:\n",
    "        item.set_linewidth(2)\n",
    "        item.set_color('k')\n",
    "\n",
    "ax1.set_xlim(-2, 2)\n",
    "ax.set_xlabel('difference to truth (m a$^{-1}$)')\n",
    "ax1.set_yticklabels([label_names[c.replace(str(v), '')].lower() for c in these_cols])\n",
    "ax1.text(-1.9, 10.7, 'a', fontsize=36)\n",
    "\n",
    "ax2.set_xlim(-2, 2)\n",
    "ax2.set_yticklabels([])\n",
    "ax2.text(-1.9, 10.7, 'b', fontsize=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows the same as above, but for a single area grouping (1-10 km2, 10-50 km2, 50-100 km2, or over 100 km2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor='w', figsize=(12, 12), dpi=200)\n",
    "v = 50 # correlation threshold\n",
    "these_cols = [c + str(v) for c in dv_cols]\n",
    "# grouped[0] is glaciers under 10 km2, grouped[3] is glaciers over 100 km2\n",
    "bp = grouped[1][these_cols].boxplot(vert=False, return_type='dict')\n",
    "\n",
    "for key in bp.keys():\n",
    "    for item in bp[key]:\n",
    "        item.set_linewidth(2)\n",
    "        item.set_color('k')\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(-2, 2)\n",
    "ax.set_xlabel('difference to truth (m a$^{-1}$)')\n",
    "ax.set_yticklabels([c.lower().replace(str(v), '') for c in these_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows how the values change for each large glacier when going from a 50% correlation threshold to a 70% correlation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c in dv_cols:\n",
    "    sorted_3_70[c + '70'] = sorted_3_70[c + '70'] - sorted_3[c + '50']\n",
    "\n",
    "y_inds = np.arange(0, sorted_3.index.size, 1)\n",
    "f = plt.figure(facecolor='w', figsize=(15, 15), dpi=200)\n",
    "\n",
    "# plot the 70% void data\n",
    "v = 70\n",
    "plt.plot([0, 0], [-1, 20], 'k--', linewidth=2)\n",
    "plt.plot(sorted_3_70['Mean dH{}'.format(v)], y_inds, 'x',\n",
    "         label='mean dH', ms=18, color='purple')\n",
    "plt.plot(sorted_3_70['Med. dH{}'.format(v)], y_inds, '+',\n",
    "         label='med. dH', ms=18, color='purple')\n",
    "\n",
    "plt.plot(sorted_3_70['dH interp.{}'.format(v)], y_inds, 'd',\n",
    "         label='dH int.', ms=18, color='r', fillstyle='none')\n",
    "plt.plot(sorted_3_70['Z interp.{}'.format(v)],  y_inds,'o',\n",
    "         label='Z int.', ms=18, color='r', fillstyle='none')\n",
    "plt.plot(sorted_3_70['1km neighborhood{}'.format(v)], y_inds, 's',\n",
    "         label='1km avg.', ms=18, color='r', fillstyle='none')\n",
    "\n",
    "plt.plot(sorted_3_70['Glob. Mean Hyps.{}'.format(v)], y_inds, '^',\n",
    "         label='glob. mean hyps.', ms=18, color='k', fillstyle='none')\n",
    "plt.plot(sorted_3_70['Glob. Med. Hyps.{}'.format(v)], y_inds, '*',\n",
    "         label='glob. med. hyps.', ms=18, color='k', fillstyle='none')\n",
    "plt.plot(sorted_3_70['Glob. Poly. Hyps.{}'.format(v)], y_inds, '.',\n",
    "         label='glob. poly. hyps.', ms=18, color='k')\n",
    "\n",
    "# local methods: use squares\n",
    "plt.plot(sorted_3_70['Loc. Mean Hyps.{}'.format(v)], y_inds, '^',\n",
    "         label='loc. mean hyps.', ms=18, color='b', fillstyle='none')\n",
    "plt.plot(sorted_3_70['Loc. Med. Hyps.{}'.format(v)], y_inds, '*',\n",
    "         label='loc. med. hyps.', ms=18, color='b', fillstyle='none')\n",
    "plt.plot(sorted_3_70['Loc. Poly. Hyps.{}'.format(v)], y_inds, '.',\n",
    "         label='loc. poly. hyps.', ms=18, color='b')\n",
    "\n",
    "plt.legend(loc='lower left', prop=legend_font)\n",
    "plt.gca().set_yticks(y_inds)\n",
    "plt.gca().set_yticklabels(sorted_3.index)\n",
    "plt.grid(axis='y')\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.ylim(-0.5, 19.5)\n",
    "\n",
    "plt.xlabel('difference to 50% threshold (m a$^{-1}$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 12\n",
    "\n",
    "Figure 12 from the paper shows how the three \"best\" methods perform as a function of percent void. This figure takes the values for all correlation thresholds and sorts them by percent void."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_df_list = []\n",
    "for v in void_list:\n",
    "    this_df = pd.DataFrame()\n",
    "    this_df['Pct Void'] = np.floor(df['Pct Void' + str(v)] / 0.08) * 0.08\n",
    "    for c in dv_cols:\n",
    "        this_df[c] = df[c + str(v)]\n",
    "    grp_df_list.append(this_df)\n",
    "\n",
    "grp_df = pd.concat(grp_df_list)\n",
    "stats_df = grp_df[dv_cols].groupby(grp_df['Pct Void']).describe()\n",
    "\n",
    "plt.figure(figsize=(15,15), facecolor='w', dpi=200)\n",
    "\n",
    "cols = ['dH interp.', 'Loc. Mean Hyps.', 'Glob. Mean Hyps.']\n",
    "for c in cols:\n",
    "    valid = stats_df[c]['count'] >= 4\n",
    "    this_mean = stats_df[c]['mean'][valid]\n",
    "    this_std = stats_df[c]['std'][valid]\n",
    "    this_up = this_mean + this_std\n",
    "    this_dn = this_mean - this_std\n",
    "    this_voids = stats_df.index.values[valid]\n",
    "\n",
    "    plt.plot(100 * (this_voids + 0.04), this_mean, method_markers[c][1],\n",
    "             linewidth=2, label=label_names[c].lower())\n",
    "    env_x = 100 * np.hstack([this_voids, 1, 1, np.flipud(this_voids), 0])\n",
    "    env_y = np.hstack([this_dn, this_dn.values[-1], this_up.values[-1], np.flipud(this_up), this_up.values[0]])\n",
    "    patchcoords = np.column_stack([env_x, env_y])\n",
    "    env_patch = Polygon(patchcoords, closed=True, facecolor=method_markers[c][1], alpha=0.15)\n",
    "    plt.gca().add_patch(env_patch)\n",
    "\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.ylabel('difference to truth (m a$^{-1}$)')\n",
    "plt.xlabel('percent void')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure is the same as above, but only for a given correlation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 90\n",
    "void_grp = np.floor(df['Pct Void' + str(v)] / 0.05) * 0.05\n",
    "df_cols = [c + str(v) for c in dv_cols]\n",
    "df['void_grp'] = void_grp\n",
    "grp_df = df[df_cols].groupby(df['void_grp']).describe()\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "cols = ['dH interp.', 'Loc. Mean Hyps.', 'Glob. Mean Hyps.']\n",
    "for c in cols:\n",
    "    valid = grp_df[c + str(v)]['count'] >= 4\n",
    "    this_mean = grp_df[c + str(v)]['mean'][valid]\n",
    "    this_std = grp_df[c + str(v)]['std'][valid]\n",
    "    this_up = this_mean + this_std\n",
    "    this_dn = this_mean - this_std\n",
    "    this_voids = grp_df.index.values[valid]\n",
    "\n",
    "    plt.plot(100 * this_voids, this_mean, method_markers[c][1], linewidth=2, label=c)\n",
    "\n",
    "    env_x = 100 * np.hstack([this_voids, np.flipud(this_voids)])\n",
    "    env_y = np.hstack([this_dn, np.flipud(this_up)])\n",
    "    patchcoords = np.column_stack([env_x, env_y])\n",
    "    env_patch = Polygon(patchcoords, closed=True, facecolor=method_markers[c][1], alpha=0.15)\n",
    "    plt.gca().add_patch(env_patch)\n",
    "\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.ylabel('difference to truth (m a$^{-1}$)')\n",
    "plt.xlabel('percent void')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the percentage of estimates that fall outside of the original uncertainty range for the top 5 methods (constant mean, interpolation of elevation chagne, global mean hypsometric, local mean and median hypsometric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_df_list = []\n",
    "for v in void_list:\n",
    "    this_df = pd.DataFrame()\n",
    "    void_grp = np.floor(df['Pct Void' + str(v)] / 0.06) * 0.06\n",
    "    this_df['Pct Void'] = void_grp\n",
    "    for c in dv_cols:\n",
    "        col = np.zeros(void_grp.shape)\n",
    "        inside = np.abs(df[c + str(v)]) < df['uncert.']\n",
    "        col[inside] = 1\n",
    "        this_df[c] = col\n",
    "    grp_df_list.append(this_df)\n",
    "\n",
    "grp_df = pd.concat(grp_df_list)\n",
    "sum_df = grp_df[dv_cols].groupby(grp_df['Pct Void']).sum()\n",
    "des_df = grp_df[dv_cols].groupby(grp_df['Pct Void']).describe()\n",
    "\n",
    "count = des_df['Mean dH']['count']\n",
    "valid = count > 5\n",
    "void_grps = sum_df.index.values\n",
    "\n",
    "plt.figure(figsize=(12,12), facecolor='w', dpi=200)\n",
    "\n",
    "cols = ['Mean dH', 'dH interp.', '1km neighborhood', 'Glob. Mean Hyps.',\n",
    "        'Loc. Mean Hyps.', 'Loc. Med. Hyps.']\n",
    "for c in cols:\n",
    "    if method_markers[c][0] == '.':\n",
    "        fs = 'full'\n",
    "    else:\n",
    "        fs = 'none'\n",
    "    plt.plot(100 * (void_grps[valid] + 0.03), 100 * sum_df[c][valid] / count[valid],\n",
    "             method_markers[c][0], color=method_markers[c][1], ms=14,\n",
    "             label=label_names[c].lower(), linewidth=10, fillstyle=fs)\n",
    "\n",
    "plt.xlabel('percent void')\n",
    "plt.ylabel('percent less than uncertainty')\n",
    "\n",
    "plt.gca().set_xlim(0, 102)\n",
    "plt.gca().set_ylim(0, 102)\n",
    "#plt.legend(loc='upper center', bbox_to_anchor=(1.2, 1.01), prop=legend_font)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the mean (± std. dev) percentage of voids per glacier for each correlation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10), facecolor='w')\n",
    "\n",
    "voids = [c for c in df.columns if 'Void' in c]\n",
    "voids.sort()\n",
    "\n",
    "mean_voids = df[voids].mean()\n",
    "std_voids = df[voids].std()\n",
    "this_up = mean_voids + std_voids\n",
    "this_dn = mean_voids - std_voids\n",
    "\n",
    "plt.plot(void_list, 100 * df[voids].mean(), 'k')\n",
    "\n",
    "env_x = np.hstack([void_list, 95, 95, np.flipud(void_list), 35])\n",
    "env_y = 100 * np.hstack([this_dn, this_dn.values[-1], this_up.values[-1], np.flipud(this_up), this_up.values[0]])\n",
    "\n",
    "patchcoords = np.column_stack([env_x, env_y])\n",
    "env_patch = Polygon(patchcoords, closed=True, facecolor='k', alpha=0.15)\n",
    "plt.gca().add_patch(env_patch)\n",
    "plt.gca().set_xlim(0, 100)\n",
    "plt.gca().set_ylim(0, 100)\n",
    "\n",
    "plt.xlabel('correlation threshold')\n",
    "plt.ylabel('mean percent void')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2\n",
    "\n",
    "Table 2 from the papers shows the results for Taku and Field Glaciers, which have the largest differences from truth in terms of total volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 50 # correlation threshold\n",
    "taku_data = df.loc[['RGI60-01.01390']]\n",
    "field_data = df.loc[['RGI60-01.01520']]\n",
    "\n",
    "print('method & Taku Glacier & Field Glacier \\\\\\\\\\hline')\n",
    "for c in dv_cols:\n",
    "    print('{} & {:.2f} & {:.2f} \\\\\\\\'.format(label_names[c].lower(), taku_data[c + str(v)].values[0],\n",
    "                                             field_data[c + str(v)].values[0]))\n",
    "\n",
    "print('pct void & {:.2f} & {:.2f} \\\\\\\\'.format(100 * taku_data['Pct Void' + str(v)].values[0],\n",
    "                                               100 * field_data['Pct Void' + str(v)].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field Glacier comparison\n",
    "Show how taking the median elevation difference is probably a bad idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 50 # correlation threshold\n",
    "ifsar = GeoImg('2013/seak.ifsar.2013.dem.30m_adj.tif')\n",
    "ifsar_srtm = GeoImg('2013/ifsar_srtm_2013_dh.tif')\n",
    "srtm = GeoImg('2013/SRTM_SE_Alaska_30m_2013IfSAR_adj.tif')\n",
    "\n",
    "aad_srtm = GeoImg('hypsometries/IfSAR_AAD_DEM_2013.tif')\n",
    "\n",
    "mask_full = GeoImg('../southeast_average_corr.tif')\n",
    "mask_sub = mask_full.reproject(ifsar)\n",
    "\n",
    "holy_ifsar_srtm = ifsar_srtm.copy()\n",
    "holy_ifsar_srtm.img[mask_sub.img < v] = np.nan\n",
    "\n",
    "gmask_tif = GeoImg('GlacierBay_Mask_2013.tif')\n",
    "glacier_mask = gmask_tif.img\n",
    "glacs = np.unique(gmask_tif.img[np.isfinite(gmask_tif.img)])\n",
    "\n",
    "glac_shp = gpd.read_file('../outlines/01_rgi60_Alaska_GlacierBay_02km_UTM_2013.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "field_mask = glacier_mask == 873 # this index may have changed - check shapefile!\n",
    "field_void_dH = holy_ifsar_srtm.img[field_mask]\n",
    "field_nonvoid_dH = ifsar_srtm.img[field_mask]\n",
    "\n",
    "bins = np.arange(-100, 25, 1)\n",
    "plt.figure(facecolor='w', figsize=(10, 5), dpi=200)\n",
    "n1, b1, p1 = plt.hist(field_void_dH[np.isfinite(field_void_dH)], bins, \n",
    "                      alpha=0.75, normed=True, label='voided', facecolor='k', edgecolor='k')\n",
    "n2, b2, p2 = plt.hist(field_nonvoid_dH[np.isfinite(field_nonvoid_dH)], bins, \n",
    "                      alpha=0.8, normed=True, label='non-voided', facecolor='0.9', edgecolor='k')\n",
    "plt.plot([np.nanmean(field_void_dH), np.nanmean(field_void_dH)], [0, 0.1], '-.', color='0.5',\n",
    "         ms=20, label='voided mean', linewidth=2)\n",
    "plt.plot([np.nanmedian(field_void_dH), np.nanmedian(field_void_dH)], [0, 0.1], 'k--', \n",
    "         ms=20, label='voided median', linewidth=2)\n",
    "# plt.plot(np.nanmean(field_nonvoid_dH), 0, 'r^', ms=12, label='non-voided mean')\n",
    "# plt.plot(np.nanmedian(field_nonvoid_dH), 0, 'r*', ms=12, label='non-voided median')\n",
    "plt.xlabel('elevation change (m)')\n",
    "plt.ylabel('frequency')\n",
    "plt.legend(prop=legend_font)\n",
    "\n",
    "plt.xlim(-100, 25)\n",
    "plt.ylim(0, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total regional volume change and uncertainty\n",
    "\n",
    "Calculates the total \"regional\" volume change (by summing all of the glaciers for which we have values), and estimates the uncertainty based on the off-glacier differences in the DEMs as well as the co-registration with ICESat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 30 # pixel size\n",
    "L = 500 # assumed autocorrelation length\n",
    "eps_a = 0.1 # assumed 10% area uncertainty\n",
    "eps_rand = 8.71 # comes from the off-glacier statistics\n",
    "eps_bias = 1.32 # comes from co-registration with ICESat\n",
    "\n",
    "dv = np.sum(df['base dV'] * df['Area']) # total in m3/yr\n",
    "area = df['Area'].sum() # total glacier area\n",
    "\n",
    "dh = dv / area # mean elevation change\n",
    "n_pix = area / r / r # number of pixels\n",
    "\n",
    "# eqn. 2 from the paper - volume change uncertainty due to dh uncertainty\n",
    "e_h = np.sqrt(eps_rand**2 / (np.sqrt(n_pix/(L/r)**2)) + eps_bias**2) * area\n",
    "# volume change uncertainty due to area uncertainty\n",
    "e_a = dv * eps_a\n",
    "\n",
    "# eqn. 3 from the paper - total uncertainty in volume change\n",
    "total_uncert = np.sqrt(e_h**2 + e_a**2) / 13.1 / area # total in m\n",
    "print('Total volume change for region: {:.2f}±{:.2f} m/yr'.format(dh, total_uncert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## volume change vs area\n",
    "\n",
    "Plot volume change vs. area for all glaciers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor='w', figsize=(8,8))\n",
    "\n",
    "plt.plot(df['Area'] / 1e6, df['base dV'], 'o')\n",
    "plt.plot([0, 600], [df['base dV'].mean(), df['base dV'].mean()], 'k--')\n",
    "\n",
    "plt.xlabel('area (km$^2$)')\n",
    "plt.ylabel('volume change (m a$^{-1}$)')\n",
    "plt.gca().set_xlim(0, 600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
